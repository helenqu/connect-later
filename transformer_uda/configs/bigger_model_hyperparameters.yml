# informer architecture hyperparams
dropout_rate: 0.35
num_encoder_layers: 8
num_decoder_layers: 8
encoder_attention_heads: 12
decoder_attention_heads: 12
encoder_ffn_dim: 256
decoder_ffn_dim: 256
d_model: 768

# data hyperparams
prediction_length: 10
context_length: 170
lags: 
  - 0
freq: "1M"
time_features:
  - "month_of_year"

# training hyperparams
batch_size: 1024
num_batches_per_epoch: 1000
# weight_decay: 0.01
lr: 1e-4

allow_padding: True
data_subset_file: null
