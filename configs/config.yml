# informer architecture hyperparameters
dropout_rate: 0.2
num_encoder_layers: 8
num_decoder_layers: 8
encoder_attention_heads: 12
decoder_attention_heads: 12
encoder_ffn_dim: 256
decoder_ffn_dim: 256
d_model: 768
scaling: null
batch_size: 256

# pretraining hyperparameters
pretrain_lr: 1e-4

# finetune hyperparameters
lp_lr: 1e-4
ft_lr: 4e-5 
classifier_dropout: 0.3
weight_decay: 0.01
